{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Computational Intelligence - PART-A",
   "id": "6a4e0f8e06d99d89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predicting Alzheimer's Disease using Neural Nets",
   "id": "de3f02886c82015c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:45.797380Z",
     "start_time": "2025-04-14T15:01:45.793594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "id": "7fd0c2845e33a0c8",
   "outputs": [],
   "execution_count": 408
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:45.811780Z",
     "start_time": "2025-04-14T15:01:45.809271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(filename):\n",
    "    try:\n",
    "        data = pd.read_csv(filename)\n",
    "        print(f\"Dataset loaded successfully: {filename}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")"
   ],
   "id": "3b91b09fe263aab5",
   "outputs": [],
   "execution_count": 409
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:45.831864Z",
     "start_time": "2025-04-14T15:01:45.827791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()"
   ],
   "id": "ba3ce042c832c196",
   "outputs": [],
   "execution_count": 410
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### EDA",
   "id": "3b3febb8361b947f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:45.857095Z",
     "start_time": "2025-04-14T15:01:45.845904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_name = 'alzheimers_disease_data.csv'\n",
    "dataset = load_dataset(file_name)\n",
    "dataset.head()"
   ],
   "id": "1fbd2b99e3ac23d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully: alzheimers_disease_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
       "0       4751   73       0          0               2  22.927749        0   \n",
       "1       4752   89       0          0               0  26.827681        0   \n",
       "2       4753   73       0          3               1  17.795882        0   \n",
       "3       4754   74       1          0               1  33.800817        1   \n",
       "4       4755   89       0          0               0  20.716974        0   \n",
       "\n",
       "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
       "0           13.297218          6.327112     1.347214  ...                 0   \n",
       "1            4.542524          7.619885     0.518767  ...                 0   \n",
       "2           19.555085          7.844988     1.826335  ...                 0   \n",
       "3           12.209266          8.428001     7.435604  ...                 0   \n",
       "4           18.454356          6.310461     0.795498  ...                 0   \n",
       "\n",
       "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
       "0                   0  1.725883          0               0   \n",
       "1                   0  2.592424          0               0   \n",
       "2                   0  7.119548          0               1   \n",
       "3                   1  6.481226          0               0   \n",
       "4                   0  0.014691          0               0   \n",
       "\n",
       "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
       "0                   0                          1              0          0   \n",
       "1                   0                          0              1          0   \n",
       "2                   0                          1              0          0   \n",
       "3                   0                          0              0          0   \n",
       "4                   1                          1              0          0   \n",
       "\n",
       "   DoctorInCharge  \n",
       "0       XXXConfid  \n",
       "1       XXXConfid  \n",
       "2       XXXConfid  \n",
       "3       XXXConfid  \n",
       "4       XXXConfid  \n",
       "\n",
       "[5 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>DoctorInCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4751</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.927749</td>\n",
       "      <td>0</td>\n",
       "      <td>13.297218</td>\n",
       "      <td>6.327112</td>\n",
       "      <td>1.347214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.725883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4752</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.827681</td>\n",
       "      <td>0</td>\n",
       "      <td>4.542524</td>\n",
       "      <td>7.619885</td>\n",
       "      <td>0.518767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.592424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4753</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.795882</td>\n",
       "      <td>0</td>\n",
       "      <td>19.555085</td>\n",
       "      <td>7.844988</td>\n",
       "      <td>1.826335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.119548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4754</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.800817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.209266</td>\n",
       "      <td>8.428001</td>\n",
       "      <td>7.435604</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.481226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4755</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.716974</td>\n",
       "      <td>0</td>\n",
       "      <td>18.454356</td>\n",
       "      <td>6.310461</td>\n",
       "      <td>0.795498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXConfid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 411
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:45.937990Z",
     "start_time": "2025-04-14T15:01:45.933560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Dataset Info:\")\n",
    "dataset.info()"
   ],
   "id": "cc4a1255275f31a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2149 entries, 0 to 2148\n",
      "Data columns (total 35 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   PatientID                  2149 non-null   int64  \n",
      " 1   Age                        2149 non-null   int64  \n",
      " 2   Gender                     2149 non-null   int64  \n",
      " 3   Ethnicity                  2149 non-null   int64  \n",
      " 4   EducationLevel             2149 non-null   int64  \n",
      " 5   BMI                        2149 non-null   float64\n",
      " 6   Smoking                    2149 non-null   int64  \n",
      " 7   AlcoholConsumption         2149 non-null   float64\n",
      " 8   PhysicalActivity           2149 non-null   float64\n",
      " 9   DietQuality                2149 non-null   float64\n",
      " 10  SleepQuality               2149 non-null   float64\n",
      " 11  FamilyHistoryAlzheimers    2149 non-null   int64  \n",
      " 12  CardiovascularDisease      2149 non-null   int64  \n",
      " 13  Diabetes                   2149 non-null   int64  \n",
      " 14  Depression                 2149 non-null   int64  \n",
      " 15  HeadInjury                 2149 non-null   int64  \n",
      " 16  Hypertension               2149 non-null   int64  \n",
      " 17  SystolicBP                 2149 non-null   int64  \n",
      " 18  DiastolicBP                2149 non-null   int64  \n",
      " 19  CholesterolTotal           2149 non-null   float64\n",
      " 20  CholesterolLDL             2149 non-null   float64\n",
      " 21  CholesterolHDL             2149 non-null   float64\n",
      " 22  CholesterolTriglycerides   2149 non-null   float64\n",
      " 23  MMSE                       2149 non-null   float64\n",
      " 24  FunctionalAssessment       2149 non-null   float64\n",
      " 25  MemoryComplaints           2149 non-null   int64  \n",
      " 26  BehavioralProblems         2149 non-null   int64  \n",
      " 27  ADL                        2149 non-null   float64\n",
      " 28  Confusion                  2149 non-null   int64  \n",
      " 29  Disorientation             2149 non-null   int64  \n",
      " 30  PersonalityChanges         2149 non-null   int64  \n",
      " 31  DifficultyCompletingTasks  2149 non-null   int64  \n",
      " 32  Forgetfulness              2149 non-null   int64  \n",
      " 33  Diagnosis                  2149 non-null   int64  \n",
      " 34  DoctorInCharge             2149 non-null   object \n",
      "dtypes: float64(12), int64(22), object(1)\n",
      "memory usage: 587.7+ KB\n"
     ]
    }
   ],
   "execution_count": 412
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.024376Z",
     "start_time": "2025-04-14T15:01:46.000651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Summary Statistics\")\n",
    "dataset.describe()"
   ],
   "id": "d05a3249ca95cb2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         PatientID          Age       Gender    Ethnicity  EducationLevel  \\\n",
       "count  2149.000000  2149.000000  2149.000000  2149.000000     2149.000000   \n",
       "mean   5825.000000    74.908795     0.506282     0.697534        1.286645   \n",
       "std     620.507185     8.990221     0.500077     0.996128        0.904527   \n",
       "min    4751.000000    60.000000     0.000000     0.000000        0.000000   \n",
       "25%    5288.000000    67.000000     0.000000     0.000000        1.000000   \n",
       "50%    5825.000000    75.000000     1.000000     0.000000        1.000000   \n",
       "75%    6362.000000    83.000000     1.000000     1.000000        2.000000   \n",
       "max    6899.000000    90.000000     1.000000     3.000000        3.000000   \n",
       "\n",
       "               BMI      Smoking  AlcoholConsumption  PhysicalActivity  \\\n",
       "count  2149.000000  2149.000000         2149.000000       2149.000000   \n",
       "mean     27.655697     0.288506           10.039442          4.920202   \n",
       "std       7.217438     0.453173            5.757910          2.857191   \n",
       "min      15.008851     0.000000            0.002003          0.003616   \n",
       "25%      21.611408     0.000000            5.139810          2.570626   \n",
       "50%      27.823924     0.000000            9.934412          4.766424   \n",
       "75%      33.869778     1.000000           15.157931          7.427899   \n",
       "max      39.992767     1.000000           19.989293          9.987429   \n",
       "\n",
       "       DietQuality  ...  FunctionalAssessment  MemoryComplaints  \\\n",
       "count  2149.000000  ...           2149.000000       2149.000000   \n",
       "mean      4.993138  ...              5.080055          0.208004   \n",
       "std       2.909055  ...              2.892743          0.405974   \n",
       "min       0.009385  ...              0.000460          0.000000   \n",
       "25%       2.458455  ...              2.566281          0.000000   \n",
       "50%       5.076087  ...              5.094439          0.000000   \n",
       "75%       7.558625  ...              7.546981          0.000000   \n",
       "max       9.998346  ...              9.996467          1.000000   \n",
       "\n",
       "       BehavioralProblems          ADL    Confusion  Disorientation  \\\n",
       "count         2149.000000  2149.000000  2149.000000     2149.000000   \n",
       "mean             0.156817     4.982958     0.205212        0.158213   \n",
       "std              0.363713     2.949775     0.403950        0.365026   \n",
       "min              0.000000     0.001288     0.000000        0.000000   \n",
       "25%              0.000000     2.342836     0.000000        0.000000   \n",
       "50%              0.000000     5.038973     0.000000        0.000000   \n",
       "75%              0.000000     7.581490     0.000000        0.000000   \n",
       "max              1.000000     9.999747     1.000000        1.000000   \n",
       "\n",
       "       PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  \\\n",
       "count         2149.000000                2149.000000    2149.000000   \n",
       "mean             0.150768                   0.158678       0.301536   \n",
       "std              0.357906                   0.365461       0.459032   \n",
       "min              0.000000                   0.000000       0.000000   \n",
       "25%              0.000000                   0.000000       0.000000   \n",
       "50%              0.000000                   0.000000       0.000000   \n",
       "75%              0.000000                   0.000000       1.000000   \n",
       "max              1.000000                   1.000000       1.000000   \n",
       "\n",
       "         Diagnosis  \n",
       "count  2149.000000  \n",
       "mean      0.353653  \n",
       "std       0.478214  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholConsumption</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>DietQuality</th>\n",
       "      <th>...</th>\n",
       "      <th>FunctionalAssessment</th>\n",
       "      <th>MemoryComplaints</th>\n",
       "      <th>BehavioralProblems</th>\n",
       "      <th>ADL</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Disorientation</th>\n",
       "      <th>PersonalityChanges</th>\n",
       "      <th>DifficultyCompletingTasks</th>\n",
       "      <th>Forgetfulness</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5825.000000</td>\n",
       "      <td>74.908795</td>\n",
       "      <td>0.506282</td>\n",
       "      <td>0.697534</td>\n",
       "      <td>1.286645</td>\n",
       "      <td>27.655697</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>10.039442</td>\n",
       "      <td>4.920202</td>\n",
       "      <td>4.993138</td>\n",
       "      <td>...</td>\n",
       "      <td>5.080055</td>\n",
       "      <td>0.208004</td>\n",
       "      <td>0.156817</td>\n",
       "      <td>4.982958</td>\n",
       "      <td>0.205212</td>\n",
       "      <td>0.158213</td>\n",
       "      <td>0.150768</td>\n",
       "      <td>0.158678</td>\n",
       "      <td>0.301536</td>\n",
       "      <td>0.353653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>620.507185</td>\n",
       "      <td>8.990221</td>\n",
       "      <td>0.500077</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>0.904527</td>\n",
       "      <td>7.217438</td>\n",
       "      <td>0.453173</td>\n",
       "      <td>5.757910</td>\n",
       "      <td>2.857191</td>\n",
       "      <td>2.909055</td>\n",
       "      <td>...</td>\n",
       "      <td>2.892743</td>\n",
       "      <td>0.405974</td>\n",
       "      <td>0.363713</td>\n",
       "      <td>2.949775</td>\n",
       "      <td>0.403950</td>\n",
       "      <td>0.365026</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>0.365461</td>\n",
       "      <td>0.459032</td>\n",
       "      <td>0.478214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4751.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.008851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.009385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5288.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.611408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.139810</td>\n",
       "      <td>2.570626</td>\n",
       "      <td>2.458455</td>\n",
       "      <td>...</td>\n",
       "      <td>2.566281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.342836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5825.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.823924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.934412</td>\n",
       "      <td>4.766424</td>\n",
       "      <td>5.076087</td>\n",
       "      <td>...</td>\n",
       "      <td>5.094439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.038973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6362.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.869778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.157931</td>\n",
       "      <td>7.427899</td>\n",
       "      <td>7.558625</td>\n",
       "      <td>...</td>\n",
       "      <td>7.546981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.581490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6899.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.992767</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.989293</td>\n",
       "      <td>9.987429</td>\n",
       "      <td>9.998346</td>\n",
       "      <td>...</td>\n",
       "      <td>9.996467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 413
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.154614Z",
     "start_time": "2025-04-14T15:01:46.145422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Some numerical features below are categorical (ordinal). Because though they have >= 10 categories we check their distribution like the numerical one's for convenience\n",
    "\n",
    "numerical_columns = [\n",
    "    'Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
    "    'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal',\n",
    "    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides',\n",
    "    'MMSE', 'FunctionalAssessment', 'ADL'\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    'Gender', 'Ethnicity', 'EducationLevel', 'Smoking', 'FamilyHistoryAlzheimers',\n",
    "    'CardiovascularDisease', 'Diabetes', 'Depression', 'HeadInjury', 'Hypertension',\n",
    "    'MemoryComplaints', 'BehavioralProblems', 'Confusion', 'Disorientation',\n",
    "    'PersonalityChanges', 'DifficultyCompletingTasks', 'Forgetfulness', 'Diagnosis'\n",
    "]\n",
    "\n",
    "def plot_histograms_separate(dataset, numerical_columns):\n",
    "    for column in numerical_columns:\n",
    "        # Create a figure with 1 row and 2 columns\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "        # Left subplot: Overall distribution\n",
    "        sns.histplot(\n",
    "            data=dataset,\n",
    "            x=column,\n",
    "            color=\"blue\",\n",
    "            kde=True,\n",
    "            bins=15,\n",
    "            ax=axes[0]\n",
    "        )\n",
    "        axes[0].set_title(f'Overall Distribution of {column}')\n",
    "        axes[0].set_xlabel(column)\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "\n",
    "        # Right subplot: Distribution by diagnosis\n",
    "        sns.histplot(\n",
    "            data=dataset,\n",
    "            x=column,\n",
    "            hue=\"Diagnosis\",\n",
    "            palette=[\"#90CAF9\", \"#F8A170\"],\n",
    "            kde=True,\n",
    "            bins=15,\n",
    "            multiple=\"layer\",\n",
    "            ax=axes[1],\n",
    "            alpha=0.6\n",
    "        )\n",
    "\n",
    "        handles, labels = axes[1].get_legend_handles_labels()\n",
    "        axes[1].legend(handles, ['No Alzheimer\\'s', 'Alzheimer\\'s'])\n",
    "\n",
    "        axes[1].set_title(f'Distribution of {column} by Diagnosis')\n",
    "        axes[1].set_xlabel(column)\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_boxplots(dataset):\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "    melted_data = pd.melt(dataset[numerical_columns])\n",
    "\n",
    "    # Create a single boxplot with all numerical columns\n",
    "    sns.boxplot(x='variable', y='value', data=melted_data, ax=ax)\n",
    "    ax.set_title('Boxplots of Numerical Features', fontsize=16)\n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_categorical_crosstabs():\n",
    "    for column in categorical_columns:\n",
    "        if column != 'Diagnosis':  # Skip the Diagnosis column itself\n",
    "            # Create a figure with 1 row and 2 columns of subplots\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n",
    "\n",
    "            # Create crosstab between current feature and Diagnosis\n",
    "            crosstab = pd.crosstab(dataset[column], dataset['Diagnosis'])\n",
    "\n",
    "            if column == 'Gender':\n",
    "                crosstab.index = ['Male', 'Female']\n",
    "            elif column == 'Ethnicity':\n",
    "                crosstab.index = ['Caucasian', 'African American', 'Asian', 'Other']\n",
    "            elif column == 'EducationLevel':\n",
    "                crosstab.index = ['None', 'High School', 'Bachelor\\'s', 'Higher']\n",
    "            elif column in ['Smoking', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
    "                          'Diabetes', 'Depression', 'HeadInjury', 'Hypertension',\n",
    "                          'MemoryComplaints', 'BehavioralProblems', 'Confusion',\n",
    "                          'Disorientation', 'PersonalityChanges',\n",
    "                          'DifficultyCompletingTasks', 'Forgetfulness']:\n",
    "                crosstab.index = ['No', 'Yes']\n",
    "\n",
    "            crosstab.columns = ['No Alzheimer\\'s', 'Alzheimer\\'s']\n",
    "\n",
    "            # Plot 1: Raw counts (left subplot)\n",
    "            ax1 = crosstab.plot(kind='bar', stacked=True, ax=axes[0])\n",
    "            axes[0].set_title(f'{column} vs. Diagnosis (Counts)', fontsize=14)\n",
    "            axes[0].set_xlabel(column, fontsize=12)\n",
    "            axes[0].set_ylabel('Count', fontsize=12)\n",
    "            axes[0].legend(title='Diagnosis')\n",
    "            axes[0].set_xticklabels(crosstab.index, rotation=0)\n",
    "\n",
    "            # Add value labels on the bars\n",
    "            for container in ax1.containers:\n",
    "                ax1.bar_label(container, label_type='center', fmt='%d')\n",
    "\n",
    "            # Plot 2: Normalized percentages (right subplot)\n",
    "            crosstab_norm = crosstab.div(crosstab.sum(axis=1), axis=0) * 100\n",
    "            ax2 = crosstab_norm.plot(kind='bar', stacked=True, ax=axes[1])\n",
    "            axes[1].set_title(f'{column} vs. Diagnosis (Normalized %)', fontsize=14)\n",
    "            axes[1].set_xlabel(column, fontsize=12)\n",
    "            axes[1].set_ylabel('Percentage (%)', fontsize=12)\n",
    "            axes[1].legend(title='Diagnosis')\n",
    "            axes[1].set_xticklabels(crosstab.index, rotation=0)\n",
    "\n",
    "            # Add percentage labels on the bars\n",
    "            for container in ax2.containers:\n",
    "                ax2.bar_label(container, label_type='center', fmt='%.1f%%')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ],
   "id": "6faf1d55b30259de",
   "outputs": [],
   "execution_count": 414
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.201845Z",
     "start_time": "2025-04-14T15:01:46.200291Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_histograms_separate(dataset, numerical_columns)",
   "id": "ec1c0f473b0e3fec",
   "outputs": [],
   "execution_count": 415
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.256362Z",
     "start_time": "2025-04-14T15:01:46.254367Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_boxplots(dataset)",
   "id": "81c7611df6c6073b",
   "outputs": [],
   "execution_count": 416
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.291368Z",
     "start_time": "2025-04-14T15:01:46.289066Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_categorical_crosstabs()",
   "id": "8b98e0f0ec7e9292",
   "outputs": [],
   "execution_count": 417
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.338737Z",
     "start_time": "2025-04-14T15:01:46.306747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = ['No', 'Yes']\n",
    "counts = dataset.Diagnosis.value_counts().tolist()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(counts, labels=categories, autopct='%1.1f%%')\n",
    "plt.title('Diagnosis Distribution')\n",
    "plt.show()"
   ],
   "id": "4d303b094f8dddb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 418
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A1: Data preprocessing and preparation",
   "id": "ca0d579b88dd908e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature Scaling - Encoding",
   "id": "b0d9b8078b55753c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Perform one-hot encoding for nominal features with more than two categories, avoiding the dummy variable trap and multicollinearity.\n",
    "Features of the dataset that fall into this category are:\n",
    "- Ethnicity\n",
    "\n",
    "\n",
    "Binary features will remain as they are."
   ],
   "id": "3e2c472b6c27d47c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.359480Z",
     "start_time": "2025-04-14T15:01:46.356813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_dataset(dataset, target_column):\n",
    "    dataset = dataset.drop(columns=['PatientID', 'DoctorInCharge'])\n",
    "\n",
    "    # Split into features and target\n",
    "    X = dataset.drop(columns=[target_column])\n",
    "    y = dataset[target_column]\n",
    "\n",
    "    return X, y"
   ],
   "id": "bfff2440f6f80f3d",
   "outputs": [],
   "execution_count": 419
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.379350Z",
     "start_time": "2025-04-14T15:01:46.376404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_and_fit_preprocessors(X_train, features_to_encode, numerical_features):\n",
    "    # Create and fit encoders on training data\n",
    "    encoders = {}\n",
    "    for feature in features_to_encode:\n",
    "        encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        encoder.fit(X_train[[feature]])\n",
    "        encoders[feature] = encoder\n",
    "\n",
    "    # Create and fit scalers on training data\n",
    "    c_scaler = None\n",
    "    mm_scaler = None\n",
    "    if numerical_features:\n",
    "        c_scaler = StandardScaler(with_std=False)  # Only center, do not standardize\n",
    "        c_scaler.fit(X_train[numerical_features])\n",
    "\n",
    "        mm_scaler = MinMaxScaler()\n",
    "        mm_scaler.fit(X_train[numerical_features])\n",
    "\n",
    "    return encoders, c_scaler, mm_scaler\n"
   ],
   "id": "a5f39cb2830d3e5",
   "outputs": [],
   "execution_count": 420
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A2 - A5",
   "id": "54d9d5e5a6df4f21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.399018Z",
     "start_time": "2025-04-14T15:01:46.395318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size=1, activation='relu', dropout_rate=0.0):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Check input_sizes\n",
    "        if not isinstance(hidden_sizes, list) or len(hidden_sizes) == 0:\n",
    "            raise ValueError(\"Hidden sizes must be a non-emtpy list\")\n",
    "\n",
    "        if activation.lower() == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation.lower() == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation.lower() == 'silu':\n",
    "            self.activation = nn.SiLU()\n",
    "        else:\n",
    "            raise ValueError(f'Activation {activation} is not supported.')\n",
    "\n",
    "        # Construct layers based on the size of the hidden_sizes list\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(self.activation)\n",
    "\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "12462eb21e0acf6f",
   "outputs": [],
   "execution_count": 421
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.432668Z",
     "start_time": "2025-04-14T15:01:46.429743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_hidden_sizes(input_size):\n",
    "    H1 = input_size // 2\n",
    "    H2 = 2 * input_size // 3\n",
    "    H3 = input_size\n",
    "    H4 = 2 * input_size\n",
    "    return [H1, H2, H3, H4]"
   ],
   "id": "e78641f8daf0578d",
   "outputs": [],
   "execution_count": 422
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.441717Z",
     "start_time": "2025-04-14T15:01:46.438309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_model_instance(input_size, hidden_sizes, config):\n",
    "    # Create model instance\n",
    "    model = Net(input_size, hidden_sizes, activation=config['activation'], dropout_rate=config['dropout_rate'])\n",
    "\n",
    "    # Define loss function for binary classification\n",
    "    loss_fun = nn.BCELoss()\n",
    "\n",
    "    # Define optimizer\n",
    "    if 'weight_decay' in config:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
    "    elif 'momentum' in config:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=config['momentum'])\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    return model, loss_fun, optimizer"
   ],
   "id": "fa7c704ee099534c",
   "outputs": [],
   "execution_count": 423
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.463714Z",
     "start_time": "2025-04-14T15:01:46.456611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, train_loader, val_loader, loss_fun, optimizer, device, config, verbose=2):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_mse = []\n",
    "    val_mse = []\n",
    "\n",
    "    patience = config['patience']\n",
    "    counter = 0\n",
    "    best_model = None\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "\n",
    "    epoch_range = tqdm(range(config['num_epochs'])) if verbose == 2 else range(config['num_epochs'])\n",
    "    for epoch in epoch_range:\n",
    "        # Train model\n",
    "        model.train()\n",
    "        batch_loss = 0.0\n",
    "        batch_mse = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Perform forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fun(outputs, labels)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            batch_mse += mse_loss(outputs, labels).item() * inputs.size(0)\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Epoch metrics calculation\n",
    "        epoch_train_loss = batch_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "        epoch_train_mse = batch_mse / len(train_loader.dataset)\n",
    "\n",
    "        # Epoch metrics storage\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        train_mse.append(epoch_train_mse)\n",
    "\n",
    "        # Evaluate model\n",
    "        model.eval()\n",
    "        batch_loss = 0.0\n",
    "        batch_mse = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = loss_fun(outputs, labels)\n",
    "                batch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                mse = mse_loss(outputs, labels)\n",
    "                batch_mse += mse.item() * inputs.size(0)\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Epoch metrics calculation for validation\n",
    "        epoch_val_loss = batch_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct / total\n",
    "        epoch_val_mse = batch_mse / len(val_loader.dataset)\n",
    "\n",
    "        # Epoch metrics storage for validation\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        val_mse.append(epoch_val_mse)\n",
    "\n",
    "        if verbose == 2:\n",
    "             print(f'Epoch {epoch+1}/{config[\"num_epochs\"]} - '\n",
    "                  f'Train Loss: {epoch_train_loss:.4f}, Train MSE: {epoch_train_mse:.4f}, Train Acc: {epoch_train_acc:.4f} - '\n",
    "                  f'Val Loss: {epoch_val_loss:.4f}, Val MSE: {epoch_val_mse:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
    "        elif verbose == 1 and ((epoch+1) % 5 == 0 or epoch == 0):\n",
    "            print(f'Epoch {epoch+1}/{config[\"num_epochs\"]} - '\n",
    "                  f'Train Loss: {epoch_train_loss:.4f}, Train MSE: {epoch_train_mse:.4f}, Train Acc: {epoch_train_acc:.4f} - '\n",
    "                  f'Val Loss: {epoch_val_loss:.4f}, Val MSE: {epoch_val_mse:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            counter = 0\n",
    "            best_model = model.state_dict().copy()\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'train_mse': train_mse,\n",
    "        'val_mse': val_mse,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }"
   ],
   "id": "6286f80bd29bad85",
   "outputs": [],
   "execution_count": 424
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.481562Z",
     "start_time": "2025-04-14T15:01:46.476274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_fold_preprocessing(X_train, X_val, y_train, y_val,features_to_encode, numerical_features, config):\n",
    "    X_train_processed = X_train.copy()\n",
    "    X_val_processed = X_val.copy()\n",
    "\n",
    "    # Create and fit preprocessors using only training data\n",
    "    encoders, c_scaler, mm_scaler = create_and_fit_preprocessors(\n",
    "        X_train, features_to_encode, numerical_features\n",
    "    )\n",
    "\n",
    "    # Apply one-hot encoding\n",
    "    for feature in features_to_encode:\n",
    "        encoder = encoders[feature]\n",
    "\n",
    "        train_encoded = encoder.transform(X_train[[feature]])\n",
    "        val_encoded = encoder.transform(X_val[[feature]])\n",
    "\n",
    "        feature_names = []\n",
    "        categories = list(encoder.categories_[0])\n",
    "        for category in categories[1:]:\n",
    "            feature_names.append(f\"{feature}_{category}\")\n",
    "\n",
    "        train_encoded_df = pd.DataFrame(train_encoded, columns=feature_names, index=X_train.index)\n",
    "        val_encoded_df = pd.DataFrame(val_encoded, columns=feature_names, index=X_val.index)\n",
    "\n",
    "        X_train_processed = X_train_processed.drop(columns=[feature])\n",
    "        X_val_processed = X_val_processed.drop(columns=[feature])\n",
    "        X_train_processed = pd.concat([X_train_processed, train_encoded_df], axis=1)\n",
    "        X_val_processed = pd.concat([X_val_processed, val_encoded_df], axis=1)\n",
    "\n",
    "    if numerical_features and c_scaler and mm_scaler:\n",
    "        X_train_processed[numerical_features] = c_scaler.transform(X_train_processed[numerical_features])\n",
    "        X_val_processed[numerical_features] = c_scaler.transform(X_val_processed[numerical_features])\n",
    "\n",
    "        X_train_processed[numerical_features] = mm_scaler.transform(X_train_processed[numerical_features])\n",
    "        X_val_processed[numerical_features] = mm_scaler.transform(X_val_processed[numerical_features])\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.tensor(X_train_processed.values, dtype=torch.float64)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float64).view(-1, 1)\n",
    "    X_val_tensor = torch.tensor(X_val_processed.values, dtype=torch.float64)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float64).view(-1, 1)\n",
    "\n",
    "    # Create tensor datasets\n",
    "    train_tensor_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_tensor_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_tensor_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_tensor_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    input_size = X_train_processed.shape[1]\n",
    "\n",
    "    return train_loader, val_loader, input_size"
   ],
   "id": "8b7407a34c9da1b7",
   "outputs": [],
   "execution_count": 425
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5-fold CV",
   "id": "733550310eb313a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.500818Z",
     "start_time": "2025-04-14T15:01:46.495759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_combined_training_plot(all_fold_metrics, title_str, param_str):\n",
    "    \"\"\"Create a combined plot of training loss across all folds\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Define colors for each fold\n",
    "    colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "    # Plot training loss for each fold\n",
    "    for fold, metrics in enumerate(all_fold_metrics):\n",
    "        plt.plot(metrics['train_losses'], label=f'Fold {fold+1}', color=colors[fold % len(colors)])\n",
    "\n",
    "    plt.title(f\"Training Loss Across Folds - {title_str}\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the combined plot\n",
    "    plt.savefig(f\"plots/combined_training_loss_{param_str}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def create_combined_validation_plot(all_fold_metrics, title_str, param_str):\n",
    "    \"\"\"Create a combined plot of validation loss across all folds\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Define colors for each fold\n",
    "    colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "    # Plot validation loss for each fold\n",
    "    for fold, metrics in enumerate(all_fold_metrics):\n",
    "        plt.plot(metrics['val_losses'], label=f'Fold {fold+1}', color=colors[fold % len(colors)])\n",
    "\n",
    "    plt.title(f\"Validation Loss Across Folds - {title_str}\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the combined plot\n",
    "    plt.savefig(f\"plots/combined_validation_loss_{param_str}.png\")\n",
    "    plt.close()\n"
   ],
   "id": "a54ad1f3967961a0",
   "outputs": [],
   "execution_count": 426
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.525389Z",
     "start_time": "2025-04-14T15:01:46.518986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_kfold_cv_for_param(k_fold, X_train_val, y_train_val, hidden_size, features_to_encode, numerical_features,\n",
    "                           config, device, experiment_type, verbose=1):\n",
    "    \"\"\"Helper function to run k-fold CV for a specific parameter configuration\"\"\"\n",
    "\n",
    "    # Initialize dictionaries to store results for this parameter value\n",
    "    fold_results = {\n",
    "        'ce_loss': [],\n",
    "        'mse': [],\n",
    "        'accuracy': [],\n",
    "        'best_val_loss': []\n",
    "    }\n",
    "\n",
    "    all_fold_metrics = []\n",
    "\n",
    "    title_str='--'\n",
    "    param_str='--'\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(k_fold.split(X_train_val, y_train_val)):\n",
    "        if verbose >= 1:\n",
    "            print(f\"\\n{'='*10} Fold {fold+1}/{config['n_folds']} {'='*10}\")\n",
    "\n",
    "        # Split the data for this fold\n",
    "        X_train_fold, X_val_fold = X_train_val.iloc[train_idx], X_train_val.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_val.iloc[train_idx], y_train_val.iloc[val_idx]\n",
    "\n",
    "        # Apply preprocessing for this fold\n",
    "        train_loader, val_loader, _ = apply_fold_preprocessing(\n",
    "            X_train_fold, X_val_fold, y_train_fold, y_val_fold,\n",
    "            features_to_encode, numerical_features, config\n",
    "        )\n",
    "\n",
    "        # Create model instance\n",
    "        net, loss_fun, optimizer = create_model_instance(input_size, hidden_size, config)\n",
    "\n",
    "        # Train model\n",
    "        net, metrics = train(net, train_loader, val_loader, loss_fun, optimizer, device, config, verbose)\n",
    "\n",
    "        # Extract metrics\n",
    "        ce_loss = metrics['val_losses'][-1]\n",
    "        mse = metrics['val_mse'][-1]\n",
    "        accuracy = metrics['val_accuracies'][-1]\n",
    "        best_val_loss = metrics['best_val_loss']\n",
    "\n",
    "        if verbose >= 1:\n",
    "            print(f\"Fold {fold+1} Results - CE Loss: {ce_loss:.4f}, MSE: {mse:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Store results for this fold\n",
    "        fold_results['ce_loss'].append(ce_loss)\n",
    "        fold_results['mse'].append(mse)\n",
    "        fold_results['accuracy'].append(accuracy)\n",
    "        fold_results['best_val_loss'].append(best_val_loss)\n",
    "\n",
    "        all_fold_metrics.append(metrics)\n",
    "\n",
    "        # Generate plot title and filename\n",
    "        if experiment_type == 'activation':\n",
    "            param_str = f\"act_{config['activation']}\"\n",
    "            title_str = f\"Activation={config['activation']}, LR={config['learning_rate']}, Hidden Size={config['hidden_size']}\"\n",
    "        elif experiment_type == 'weight_decay':\n",
    "            param_str = f\"wd{config['weight_decay']}\"\n",
    "            title_str = f\"Weight Decay={config['weight_decay']}, Hidden Size={config['hidden_size']}, LR={config['learning_rate']}, Momentum={config['momentum']}, Activation={config['activation']}\"\n",
    "        elif experiment_type == 'lr_momentum':\n",
    "            param_str = f\"lr{config['learning_rate']}_mom{config['momentum']}\"\n",
    "            title_str = f\"LR={config['learning_rate']}, Momentum={config['momentum']}, Hidden Size={config['hidden_size']}, Activation={config['activation']}\"\n",
    "        elif experiment_type == 'deep_net':\n",
    "            # Deep network\n",
    "            param_str = f\"layers_{'x'.join(str(x) for x in hidden_size)}\"\n",
    "            title_str = f\"Layers={hidden_size}, Weight Decay={config['weight_decay']}, LR={config['learning_rate']}, Momentum={config['momentum']}, Activation={config['activation']}\"\n",
    "        elif experiment_type == 'hidden_size':\n",
    "            # Single hidden layer\n",
    "            h_size = hidden_size[0] if isinstance(hidden_size, list) else hidden_size\n",
    "            param_str = f\"h{h_size}\"\n",
    "            title_str = f\"Hidden Size={h_size}, LR={config['learning_rate']}\"\n",
    "\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Create combined plots after all folds are finished\n",
    "    create_combined_training_plot(all_fold_metrics, title_str, param_str)\n",
    "    create_combined_validation_plot(all_fold_metrics, title_str, param_str)\n",
    "\n",
    "    # Calculate average results across all folds\n",
    "    avg_results = {metric: np.mean(values) for metric, values in fold_results.items()}\n",
    "\n",
    "    return avg_results"
   ],
   "id": "39d623222f11282d",
   "outputs": [],
   "execution_count": 427
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:01:46.566197Z",
     "start_time": "2025-04-14T15:01:46.555166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stratified_k_fold(X_train_val, y_train_val, experiment_config, base_config, features_to_encode, numerical_features, verbose=2):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    os.makedirs(\"plots/\", exist_ok=True)\n",
    "\n",
    "    # Init stratified k-fold cross validation\n",
    "    k_fold = StratifiedKFold(n_splits=base_config['n_folds'], shuffle=True, random_state=42)\n",
    "\n",
    "    experiment_type = experiment_config['type']\n",
    "    experiment_results = {}\n",
    "\n",
    "    if experiment_type == 'hidden_size':\n",
    "        hidden_sizes = experiment_config['hidden_sizes']\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if verbose >= 1:\n",
    "                 print(f\"\\n{'='*20} Testing hidden size: {hidden_size[0]} {'='*20}\")\n",
    "\n",
    "            # Run k-fold CV for this hidden size\n",
    "            results = run_kfold_cv_for_param(\n",
    "                k_fold, X_train_val, y_train_val, hidden_size=hidden_size,\n",
    "                features_to_encode=features_to_encode, numerical_features=numerical_features,\n",
    "                config=base_config, device=device, experiment_type=experiment_type, verbose=verbose\n",
    "            )\n",
    "\n",
    "            experiment_results[hidden_size[0]] = results\n",
    "\n",
    "    elif experiment_type == 'activation':\n",
    "        # For activation function experiments\n",
    "        activation_functions = experiment_config['functions']\n",
    "        hidden_size = experiment_config['hidden_size']\n",
    "\n",
    "        for activation in activation_functions:\n",
    "            if verbose >= 1:\n",
    "                print(f\"\\n{'='*20} Testing activation function: {activation} {'='*20}\")\n",
    "\n",
    "            # Create modified config with the activation function\n",
    "            temp_config = base_config.copy()\n",
    "            temp_config['activation'] = activation\n",
    "            temp_config['hidden_size'] = hidden_size\n",
    "\n",
    "            # Run k-fold CV for this activation function\n",
    "            results = run_kfold_cv_for_param(\n",
    "                k_fold, X_train_val, y_train_val, hidden_size=hidden_size,\n",
    "                features_to_encode=features_to_encode, numerical_features=numerical_features,\n",
    "                config=temp_config, device=device, experiment_type=experiment_type, verbose=verbose\n",
    "            )\n",
    "\n",
    "            experiment_results[activation] = results\n",
    "\n",
    "    elif experiment_type == 'lr_momentum':\n",
    "        # For lr_momentum experiments, we test specific combinations\n",
    "        param_combinations = experiment_config['combinations']\n",
    "        hidden_size = experiment_config['hidden_size']\n",
    "\n",
    "        for lr, momentum in param_combinations:\n",
    "            if verbose >= 1:\n",
    "                print(f\"\\n{'='*20} Testing lr={lr}, momentum={momentum} {'='*20}\")\n",
    "\n",
    "            # Create modified config for this combination\n",
    "            temp_config = base_config.copy()\n",
    "            temp_config['learning_rate'] = lr\n",
    "            temp_config['momentum'] = momentum\n",
    "            temp_config['hidden_size'] = hidden_size\n",
    "\n",
    "            # Run k-fold CV for this combination\n",
    "            results = run_kfold_cv_for_param(\n",
    "                k_fold, X_train_val, y_train_val, hidden_size=hidden_size,\n",
    "                features_to_encode=features_to_encode, numerical_features=numerical_features,\n",
    "                config=temp_config, device=device, experiment_type=experiment_type, verbose=verbose\n",
    "            )\n",
    "\n",
    "            experiment_results[(lr, momentum)] = results\n",
    "\n",
    "    elif experiment_type == 'weight_decay':\n",
    "        # For weight decay experiments\n",
    "        weigh_decay_values = experiment_config['weight_decay']\n",
    "        hidden_size = experiment_config['hidden_size']\n",
    "\n",
    "        learning_rate = experiment_config['learning_rate']\n",
    "        momentum = experiment_config['momentum']\n",
    "\n",
    "        for weight_decay in weigh_decay_values:\n",
    "            if verbose >= 1:\n",
    "                print(f\"\\n{'='*20} Testing weight decay: {weight_decay} {'='*20}\")\n",
    "\n",
    "\n",
    "\n",
    "            # Create modified config with the weight decay value\n",
    "            temp_config = base_config.copy()\n",
    "            temp_config['learning_rate'] = learning_rate\n",
    "            temp_config['momentum'] = momentum\n",
    "            temp_config['weight_decay'] = weight_decay\n",
    "            temp_config['hidden_size'] = hidden_size\n",
    "\n",
    "            # Run k-fold CV for this weight decay\n",
    "            results = run_kfold_cv_for_param(\n",
    "                k_fold, X_train_val, y_train_val, hidden_size=hidden_size,\n",
    "                features_to_encode=features_to_encode, numerical_features=numerical_features,\n",
    "                config=temp_config, device=device, experiment_type=experiment_type, verbose=verbose\n",
    "            )\n",
    "\n",
    "            experiment_results[weight_decay] = results\n",
    "\n",
    "    elif experiment_type == 'deep_net':\n",
    "        layer_configs = experiment_config['layer_configs']\n",
    "\n",
    "        learning_rate = experiment_config['learning_rate']\n",
    "        momentum = experiment_config['momentum']\n",
    "        weight_decay = experiment_config['weight_decay']\n",
    "        dropout_rate = experiment_config['dropout_rate']\n",
    "\n",
    "        for layer_config in layer_configs:\n",
    "            config_name = \"x\".join([str(size) for size in layer_config])\n",
    "            if verbose >= 1:\n",
    "                print(f\"\\n{'='*20} Testing layer configuration: {config_name} {'='*20}\")\n",
    "\n",
    "            temp_config = base_config.copy()\n",
    "            temp_config['learning_rate'] = learning_rate\n",
    "            temp_config['momentum'] = momentum\n",
    "            temp_config['weight_decay'] = weight_decay\n",
    "            temp_config['dropout_rate'] = dropout_rate\n",
    "\n",
    "            # Run k-fold CV for this layer configuration\n",
    "            results = run_kfold_cv_for_param(\n",
    "                k_fold, X_train_val, y_train_val,\n",
    "                hidden_size=layer_config,\n",
    "                features_to_encode=features_to_encode, numerical_features=numerical_features,\n",
    "                config=temp_config, device=device, experiment_type=experiment_type, verbose=verbose\n",
    "            )\n",
    "\n",
    "            experiment_results[tuple(layer_config)] = results\n",
    "\n",
    "\n",
    "    # Print summary table\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Summary Results Table - {experiment_type}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    if experiment_type == 'lr_momentum':\n",
    "        print(f\"{'Learning Rate':<15} {'Momentum':<15} {'CE Loss':<15} {'MSE':<15} {'Accuracy':<15}\")\n",
    "        print(\"-\"*75)\n",
    "        for (lr, momentum) in experiment_results:\n",
    "            result = experiment_results[(lr, momentum)]\n",
    "            print(f\"{lr:<15} {momentum:<15} {result['ce_loss']:<15.4f} \"\n",
    "                  f\"{result['mse']:<15.4f} {result['accuracy']:<15.4f}\")\n",
    "    elif experiment_type == 'activation':\n",
    "        print(f\"{'Activation':<15} {'CE Loss':<15} {'MSE':<15} {'Accuracy':<15}\")\n",
    "        print(\"-\"*60)\n",
    "        for activation in experiment_results:\n",
    "            result = experiment_results[activation]\n",
    "            print(f\"{activation:<15} {result['ce_loss']:<15.4f} \"\n",
    "                  f\"{result['mse']:<15.4f} {result['accuracy']:<15.4f}\")\n",
    "    elif experiment_type == 'deep_net':\n",
    "        print(f\"{'Layer Config':<25} {'CE Loss':<15} {'MSE':<15} {'Accuracy':<15}\")\n",
    "        print(\"-\"*70)\n",
    "        for base_config in experiment_results:\n",
    "            result = experiment_results[base_config]\n",
    "            # Format the layer configuration as a string\n",
    "            config_str = \"x\".join([str(size) for size in base_config])\n",
    "            print(f\"{config_str:<25} {result['ce_loss']:<15.4f} \"\n",
    "                  f\"{result['mse']:<15.4f} {result['accuracy']:<15.4f}\")\n",
    "    else:\n",
    "        param_name = {'hidden_size': 'Hidden Size', 'weight_decay': 'Weight Decay'}[experiment_type]\n",
    "        print(f\"{param_name:<15} {'CE Loss':<15} {'MSE':<15} {'Accuracy':<15}\")\n",
    "        print(\"-\"*60)\n",
    "        for param in experiment_results:\n",
    "            result = experiment_results[param]\n",
    "            print(f\"{param:<15} {result['ce_loss']:<15.4f} \"\n",
    "                  f\"{result['mse']:<15.4f} {result['accuracy']:<15.4f}\")\n",
    "\n",
    "    return experiment_results"
   ],
   "id": "ff8244b96daa2281",
   "outputs": [],
   "execution_count": 428
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:05:23.314955Z",
     "start_time": "2025-04-14T15:01:46.582114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_column = 'Diagnosis'\n",
    "features_to_encode = ['Ethnicity']\n",
    "\n",
    "numerical_columns = [\n",
    "    'Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
    "    'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal',\n",
    "    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides',\n",
    "    'MMSE', 'FunctionalAssessment', 'ADL'\n",
    "]\n",
    "\n",
    "config = {\n",
    "    # Core parameters\n",
    "    'n_folds': 5,\n",
    "    'batch_size': 16,\n",
    "    'input_size': 34,\n",
    "    'num_epochs': 2000,\n",
    "    'patience': 10,\n",
    "\n",
    "    # Default hyperparameters (might be overridden in some experiments)\n",
    "    'learning_rate': 0.001,\n",
    "    'momentum': 0.0,\n",
    "    'activation': 'relu',\n",
    "    'weight_decay': 0.0,\n",
    "    'dropout_rate': 0.0\n",
    "}\n",
    "\n",
    "verbose = 0\n",
    "\n",
    "# Preprocess dataset\n",
    "X, y = preprocess_dataset(dataset, target_column)\n",
    "\n",
    "input_size = config['input_size']\n",
    "\n",
    "hidden_size_config = {\n",
    "    'type': 'hidden_size',\n",
    "    'hidden_sizes': [[size] for size in get_hidden_sizes(input_size)] # List of single element lists\n",
    "}\n",
    "\n",
    "activation_config = {\n",
    "    'type': 'activation',\n",
    "    'functions': ['relu', 'tanh', 'silu'],\n",
    "    'hidden_size': [34]  # Use best hidden size from A2 experiment\n",
    "}\n",
    "\n",
    "lr_momentum_config = {\n",
    "    'type': 'lr_momentum',\n",
    "    'combinations': [\n",
    "        (0.001, 0.2),  # First combination: learning_rate=0.001, momentum=0.2\n",
    "        (0.001, 0.6),  # Second combination: learning_rate=0.001, momentum=0.6\n",
    "        (0.05, 0.6),   # Third combination: learning_rate=0.05, momentum=0.6\n",
    "        (0.1, 0.6)     # Fourth combination: learning_rate=0.1, momentum=0.6\n",
    "    ],\n",
    "    'hidden_size': [4]\n",
    "}\n",
    "\n",
    "weight_decay_config = {\n",
    "    'type': 'weight_decay',\n",
    "    'weight_decay': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': 0.001,\n",
    "    'momentum': 0.2,\n",
    "    'hidden_size': [4]\n",
    "}\n",
    "\n",
    "deep_net_config = {\n",
    "    'type': 'deep_net',\n",
    "    'layer_configs': [\n",
    "        # Two hidden layers\n",
    "        [input_size//2, input_size//2],               # Same size\n",
    "        [input_size, input_size//2],                  # Decreasing\n",
    "        [input_size//2, input_size],                  # Increasing\n",
    "\n",
    "        # Three hidden layers\n",
    "        [input_size//2, input_size//2, input_size//2], # Same size\n",
    "        [input_size, input_size//2, input_size//4],     # Decreasing\n",
    "        [input_size//4, input_size//2, input_size]      # Increasing\n",
    "    ],\n",
    "    'weight_decay': 0.0001,\n",
    "    'momentum': 0.2,\n",
    "    'learning_rate': 0.001,\n",
    "}\n",
    "\n",
    "exp_config = hidden_size_config\n",
    "\n",
    "experiment_results = stratified_k_fold(\n",
    "    X,\n",
    "    y,\n",
    "    exp_config,\n",
    "    config,\n",
    "    features_to_encode,\n",
    "    numerical_columns,\n",
    "    verbose=verbose  # Set verbosity level\n",
    ")"
   ],
   "id": "290f592c9b1a964a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 533\n",
      "Early stopping triggered at epoch 565\n",
      "Early stopping triggered at epoch 443\n",
      "Early stopping triggered at epoch 421\n",
      "Early stopping triggered at epoch 511\n",
      "Early stopping triggered at epoch 558\n",
      "Early stopping triggered at epoch 523\n",
      "Early stopping triggered at epoch 434\n",
      "Early stopping triggered at epoch 462\n",
      "Early stopping triggered at epoch 474\n",
      "Early stopping triggered at epoch 482\n",
      "Early stopping triggered at epoch 553\n",
      "Early stopping triggered at epoch 446\n",
      "Early stopping triggered at epoch 437\n",
      "Early stopping triggered at epoch 528\n",
      "Early stopping triggered at epoch 709\n",
      "Early stopping triggered at epoch 567\n",
      "Early stopping triggered at epoch 478\n",
      "Early stopping triggered at epoch 391\n",
      "Early stopping triggered at epoch 438\n",
      "\n",
      "============================================================\n",
      "Summary Results Table - hidden_size\n",
      "============================================================\n",
      "Hidden Size     CE Loss         MSE             Accuracy       \n",
      "------------------------------------------------------------\n",
      "17              0.3882          0.1199          0.8357         \n",
      "22              0.3885          0.1199          0.8348         \n",
      "34              0.3875          0.1197          0.8362         \n",
      "68              0.3872          0.1196          0.8367         \n"
     ]
    }
   ],
   "execution_count": 429
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
